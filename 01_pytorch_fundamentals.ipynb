{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPyQeDQASYQQxct/i1hpKza",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kekele-star/pytorch_course/blob/main/01_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
        "\n",
        "* Reshaping - reshapes an input tensor to a defined shape\n",
        "* View - return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
        "* Stacking - combine multiple tensors on top of each other(vstack) or side by side(hstack)\n",
        "* Squeeze - removes all `1` dimensions form a tensor\n",
        "* Unsqueeze - add a `1` dimension to a target tensor\n",
        "* Permute - return a view of the input with dimensions permuted (swapped) in a certain way"
      ],
      "metadata": {
        "id": "mtaPkR8b0Upw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFIifapz0Sn2",
        "outputId": "f073de59-c119-4371-e82e-6e7fd7b68f91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# create a tensor\n",
        "import torch\n",
        "x = torch.arange(1., 10.)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra dimension\n",
        "x_reshaped = x.reshape(1, 9)\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "id": "1O9JAEl12RS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df5347cf-f51f-4e84-a988-163183de5776"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change the view\n",
        "z = x.view(1, 9)\n",
        "z, z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLxQ3ZrE6IUE",
        "outputId": "6380470a-cdca-48a7-b36e-35d88dddd2ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changing z changes x (because a view of a tensor shares the same memory as the original inputb\n",
        "z[:, 0] = 5\n",
        "z, x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9HZUKhAyKmM",
        "outputId": "b107f8e5-44e7-41c4-cdce-b116139a38c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
              " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack tensors on top of each other\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
        "x_stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4QObZ4F60ks",
        "outputId": "d7650a74-e252-4d69-9a9b-52cae1478c91"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.squeeze() - removes all single dimensions from a target tensor\n",
        "print(f\"Previous tensors: {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped}\")\n",
        "\n",
        "# Remove extra dimensions form x_reshaped\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {x_reshaped}\")\n",
        "print(f\"New shape: {x_reshaped.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3diERKGb9zGj",
        "outputId": "ec3a4012-32bc-44c1-b10c-1d871ab9cd7b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensors: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "Previous shape: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "\n",
            "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "New shape: torch.Size([1, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.unsqueeze() - adds a single dimension to a target tensor at a specific dim(dimension)\n",
        "print(f\"Previous target: {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped}\")\n",
        "\n",
        "\n",
        "# Add an extra dimension with unsqueeze\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=1)\n",
        "print(f\"\\nNew tensor: {x_reshaped}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75z4J3Ch_5Hg",
        "outputId": "45419a5f-53d2-4d8b-9e6d-1d21cbb4ec4e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous target: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "Previous shape: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "\n",
            "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "New shape: torch.Size([9, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.permute - rearrange the dimensions of a target tensor in a specified order\n",
        "x_original = torch.rand(size=(224, 224, 3))  # [height, width, colour_channels]\n",
        "\n",
        "# Permute the original tensor to rearrange the axis(or dim) order\n",
        "x_permuted = x_original.permute(2, 0, 1)  # shifts axis 0->1, 1->2, 2->0\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\")  # [colour_channels, height, width]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giGClVUwEtFF",
        "outputId": "3fe25056-b1fd-4fdc-cc4c-1cf8a27d8272"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_reshaped.squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeelPDY-A0Cd",
        "outputId": "e7d539e9-3673-4a41-fc60-9d5fafd17317"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexing (select data from tensors)\n",
        "Indexing with PyTorch is similar to indexing with NumPy"
      ],
      "metadata": {
        "id": "wyoty06FITYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEfhEVWuITEk",
        "outputId": "529f644c-21d0-4e41-d23a-12a9273d78bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQnRt6_xK9Ww",
        "outputId": "2a964dca-9a11-4ad8-c0ce-2cf91bb0760c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's index on the middle bracket(dim=1)\n",
        "x[0, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3iYJLqeLCDe",
        "outputId": "29dd8d95-e93f-427d-86c7-327b22555882"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's index on the most inner bracket i.e last dimension\n",
        "x[0][0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYZJEOvHLIWA",
        "outputId": "e44ceee0-1e2b-4e4b-aa2d-0c0f38143268"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can also use \":\" to select \"all\" of a target dimension\n",
        "x[:, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0CyqDGeLrGV",
        "outputId": "c23d8f28-9ccd-4aed-8fa3-2c35bcac6baa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all values of 0th and 1st dimensions but only index 1 of 2nd dimensions\n",
        "x[:, :, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKxh-fciP-gL",
        "outputId": "da448854-accc-4c49-acb2-323d4d0295cf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all values of the 0 of 0th and 1st dimension and all values of 2nd dimension\n",
        "x [0, 0, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtxC3CRrQICP",
        "outputId": "8a3445fc-1175-4c8e-c104-dd4f76cc0e91"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Index on x to return 9\n",
        "print(x[0][2][2])\n",
        "\n",
        "# Index on x to return 3, 6, 9\n",
        "print(x[:, :, 2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKYXZ6oaQi71",
        "outputId": "6c4bb98e-6a43-4c91-d27a-3c24f765b5f0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9)\n",
            "tensor([[3, 6, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch tensors & NumPy\n",
        "\n",
        "NumPy is a popular scientific Python numerical computing library.\n",
        "And because of this, PyTorch has functionality to interact with it.\n",
        "\n",
        "* Data in NumPy, want in PyTorch tensor -> `torch.form_numpy(ndarray)`\n",
        "* PyTorch tensor -> NumPy -> `torch.Tensor.numpy()`\n"
      ],
      "metadata": {
        "id": "DaPbPs0GRS7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array) #warningL when converting form numpy to pytorch, pytorch reflects numpy's default datatype of float64 unless specified otherwise\n",
        "array, tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NRFWUu6Q3kT",
        "outputId": "f51b0ec0-5ed8-4555-b3fe-9ff64f1e6406"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjy51wK2YNzA",
        "outputId": "9abf4b1b-7689-43d1-ff8d-9ca5612832bf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the value of array, what will this do to `tensor`?\n",
        "array = array + 1\n",
        "array, tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5397U4SoY8Io",
        "outputId": "0b926850-b138-40ac-e251-49b2141c03c9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor to NumPy array\n",
        "tensor = torch.ones(7)\n",
        "numpy_tensor = tensor.numpy()\n",
        "tensor, numpy_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t47kI1MnZGkk",
        "outputId": "c574e7bd-0477-4f48-840e-2e88e3d00299"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reproducbility (trying to take random out of random)\n",
        "\n",
        "In short how a neural network learns:\n",
        "`start with random numbers -> tensor operations -> update random numbers to try and make them better representation of the data -> again -> again -> again ...\n",
        "\n",
        "To reduce the randomness in neural networks and PyTorch comes the concept of a **random seed**.\n",
        "\n",
        "Essentially what the random seed does is \"flavour\" the randomness."
      ],
      "metadata": {
        "id": "DFXXN_2Oba8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# create two random tensors\n",
        "random_tensor_A = torch.rand(3, 4)\n",
        "random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(random_tensor_A)\n",
        "print(random_tensor_B)\n",
        "print(random_tensor_A == random_tensor_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ0a5qefFut1",
        "outputId": "740fa1cc-0170-4b4a-a42a-ea8536fe3b34"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4415, 0.0415, 0.1181, 0.4164],\n",
            "        [0.7435, 0.9569, 0.1342, 0.9313],\n",
            "        [0.2786, 0.4968, 0.7848, 0.4867]])\n",
            "tensor([[0.1924, 0.9877, 0.3835, 0.6757],\n",
            "        [0.4519, 0.4097, 0.6797, 0.0520],\n",
            "        [0.8273, 0.1587, 0.0303, 0.2159]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make some random but reproducible tensors\n",
        "import torch\n",
        "\n",
        "# Set the random seed\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(random_tensor_C)\n",
        "print(random_tensor_D)\n",
        "print(random_tensor_C == random_tensor_D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAZTJoqhHumr",
        "outputId": "d74ab426-d3f2-4285-cb20-28c229b1516c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
            "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
            "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running tensors and PyTorch objects on the GPUs (and making faster computations)\n",
        "\n",
        "GPUs = faster computation on numbers, thanks to cUDA + NVIDIA hardware + PyTorch working behind the scenes to make everything hunky dory(good)."
      ],
      "metadata": {
        "id": "WAuPgU6TKXOg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Getting a GPU\n",
        "\n",
        "1. Easiest - Use Google Colab for a free GPU (options to upgrade as well)\n",
        "2. Use your own GPU - takes a little bit of setup and requires the investment of purchasing a GPU, there's lots of options ..., see this post for what options to get: https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/\n",
        "3. Use cloud computing - GCP, AWS, Azure, these services allow you to rent computers on the cloud and access them\n",
        "\n",
        "For 2, 3 PyTorch + GPU drivers (CUDA) takes a little bit of setting up. To do this, refer to PyTorch setup documentation: https://pytorch.org./get-started/locally/\n",
        "\n"
      ],
      "metadata": {
        "id": "C6se9qvON7Y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abaX9KnYPDah",
        "outputId": "77d3293c-8cd2-42be-99c2-1d2361fb3cce"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jul 31 12:20:59 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Check for GPU access with PyTorch"
      ],
      "metadata": {
        "id": "_T-lIzgRW9OB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU access with PyTorch\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjsPacMrXDCu",
        "outputId": "feb2f4ed-cb1e-4778-f340-6700c61bb9ab"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For PyTorch since it's capable of running compute on the GPU or CPU, it's best practice to setup device agnostic code: https://pytorch.org/docs/stable/notes/cuda.html#best-practices.\n",
        "\n",
        "Eg: run on GPU if available, else default to CPU\n",
        "\n",
        "\n",
        "Setting up device agnostic code means creating software or code that can run on different devices without requiring significant modifications or adaptations for each specific device. In other words, it's about making your code flexible enough to work seamlessly across various platforms, such as computers, smartphones, tablets, and other devices, without having to rewrite large portions\n",
        "of the code for each one.\n",
        "\n"
      ],
      "metadata": {
        "id": "XtZBJI5lZ3gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CQswmVYqX6sH",
        "outputId": "bf5aa7eb-70fd-493b-f37c-b22f7a29fb26"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of CPUs\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18fckgI3Zf1p",
        "outputId": "822e3717-2b79-4b99-d89b-33be5754df54"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Putting tensors (and models) on the GPU\n",
        "\n",
        "The reason we want our tensors/models on the GPU is because using a GPU results in faster computations."
      ],
      "metadata": {
        "id": "_wloGklM4x2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor (default on the CPU)\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Tensor not on GPU\n",
        "print(tensor, tensor.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLc8vnlx5A04",
        "outputId": "d04e561e-af7b-43f2-e87a-57388ac80b02"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN4HG95X5XNd",
        "outputId": "3ddfc182-85b3-442e-99eb-e34bd652998b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moving tensors back to the CPU"
      ],
      "metadata": {
        "id": "sX4fpDXi5-Z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_on_gpu.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "V1Ua58WJ6CVU",
        "outputId": "50d03d6a-404b-4775-e7a4-65bb04f04989"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-e0c96c7436fd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensor_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To fix the GPU tensor with NumPy issue, we can first set it to the cPU\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqQkdyiQ6JHx",
        "outputId": "19fa469c-e29f-4b85-c68a-2a5986361f3b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_on_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2wYFEHg6b0J",
        "outputId": "0cde7906-6b28-4605-904c-ebe2452ca401"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}